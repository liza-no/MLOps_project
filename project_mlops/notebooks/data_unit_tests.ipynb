{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c52c5b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e39829d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw = pd.read_csv('../data/01_raw/booking.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b8b6cb",
   "metadata": {},
   "source": [
    "## Data unit test for raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b93e45a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: great_expectations in c:\\users\\liza_n\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.5.2)\n",
      "Requirement already satisfied: altair<5.0.0,>=4.2.1 in c:\\users\\liza_n\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from great_expectations) (4.2.2)\n",
      "Requirement already satisfied: cryptography>=3.2 in c:\\users\\liza_n\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from great_expectations) (45.0.4)\n",
      "Requirement already satisfied: jinja2>=3 in c:\\users\\liza_n\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from great_expectations) (3.1.3)\n",
      "Requirement already satisfied: jsonschema>=2.5.1 in c:\\users\\liza_n\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from great_expectations) (4.22.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.7.1 in c:\\users\\liza_n\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from great_expectations) (3.26.1)\n",
      "Requirement already satisfied: mistune>=0.8.4 in c:\\users\\liza_n\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from great_expectations) (3.0.2)\n",
      "Requirement already satisfied: packaging in c:\\users\\liza_n\\appdata\\roaming\\python\\python311\\site-packages (from great_expectations) (23.2)\n",
      "Requirement already satisfied: posthog<4,>3 in c:\\users\\liza_n\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from great_expectations) (3.25.0)\n",
      "Requirement already satisfied: pydantic>=1.10.7 in c:\\users\\liza_n\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from great_expectations) (1.10.18)\n",
      "Requirement already satisfied: pyparsing>=2.4 in c:\\users\\liza_n\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from great_expectations) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\liza_n\\appdata\\roaming\\python\\python311\\site-packages (from great_expectations) (2.8.2)\n",
      "Requirement already satisfied: requests>=2.20 in c:\\users\\liza_n\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from great_expectations) (2.32.3)\n",
      "Requirement already satisfied: ruamel.yaml>=0.16 in c:\\users\\liza_n\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from great_expectations) (0.18.14)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\liza_n\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from great_expectations) (1.10.0)\n",
      "Requirement already satisfied: tqdm>=4.59.0 in c:\\users\\liza_n\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from great_expectations) (4.64.1)\n",
      "Requirement already satisfied: typing-extensions>=4.1.0 in c:\\users\\liza_n\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from great_expectations) (4.9.0)\n",
      "Requirement already satisfied: tzlocal>=1.2 in c:\\users\\liza_n\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from great_expectations) (5.3.1)\n",
      "Requirement already satisfied: numpy>=1.22.4 in c:\\users\\liza_n\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from great_expectations) (1.23.5)\n",
      "Requirement already satisfied: pandas<2.2,>=1.3.0 in c:\\users\\liza_n\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from great_expectations) (1.5.3)\n",
      "Requirement already satisfied: entrypoints in c:\\users\\liza_n\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from altair<5.0.0,>=4.2.1->great_expectations) (0.4)\n",
      "Requirement already satisfied: toolz in c:\\users\\liza_n\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from altair<5.0.0,>=4.2.1->great_expectations) (1.0.0)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\liza_n\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from cryptography>=3.2->great_expectations) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\liza_n\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jinja2>=3->great_expectations) (2.1.5)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\liza_n\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jsonschema>=2.5.1->great_expectations) (23.2.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\liza_n\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jsonschema>=2.5.1->great_expectations) (2023.12.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\liza_n\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jsonschema>=2.5.1->great_expectations) (0.35.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\liza_n\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jsonschema>=2.5.1->great_expectations) (0.18.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\liza_n\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas<2.2,>=1.3.0->great_expectations) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\liza_n\\appdata\\roaming\\python\\python311\\site-packages (from posthog<4,>3->great_expectations) (1.16.0)\n",
      "Requirement already satisfied: monotonic>=1.5 in c:\\users\\liza_n\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from posthog<4,>3->great_expectations) (1.6)\n",
      "Requirement already satisfied: backoff>=1.10.0 in c:\\users\\liza_n\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from posthog<4,>3->great_expectations) (2.2.1)\n",
      "Requirement already satisfied: distro>=1.5.0 in c:\\users\\liza_n\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from posthog<4,>3->great_expectations) (1.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\liza_n\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.20->great_expectations) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\liza_n\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.20->great_expectations) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\liza_n\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.20->great_expectations) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\liza_n\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.20->great_expectations) (2024.2.2)\n",
      "Requirement already satisfied: ruamel.yaml.clib>=0.2.7 in c:\\users\\liza_n\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ruamel.yaml>=0.16->great_expectations) (0.2.12)\n",
      "Requirement already satisfied: colorama in c:\\users\\liza_n\\appdata\\roaming\\python\\python311\\site-packages (from tqdm>=4.59.0->great_expectations) (0.4.6)\n",
      "Requirement already satisfied: tzdata in c:\\users\\liza_n\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tzlocal>=1.2->great_expectations) (2024.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\liza_n\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from cffi>=1.14->cryptography>=3.2->great_expectations) (2.22)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.1.1\n",
      "[notice] To update, run: C:\\Users\\Liza_N\\AppData\\Local\\Programs\\Python\\Python311\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install great_expectations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f7dcc35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import great_expectations as gx\n",
    "\n",
    "\n",
    "context = gx.get_context(context_root_dir=\"../great_expectations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f77a22e7",
   "metadata": {},
   "source": [
    "First layer of expectations on raw data: \n",
    "- schema\n",
    "- datatypes (not formatted)\n",
    "- logical expectations (a booking should be for at least 1 person for at least 1 night)\n",
    "- target values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d93cd24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a custom expectations on sum of values in two columns\n",
    "from great_expectations.expectations.expectation import ColumnPairMapExpectation\n",
    "\n",
    "\n",
    "class ExpectColumnPairSumGreaterThanZero(ColumnPairMapExpectation):\n",
    "    map_metric = \"column_pair.sum_greater_than_zero\"\n",
    "    success_keys = (\"column_A\", \"column_B\")\n",
    "\n",
    "    def validate_configuration(self, configuration):\n",
    "        assert \"column_A\" in configuration.kwargs and \"column_B\" in configuration.kwargs, \\\n",
    "            \"Must specify column_A and column_B\"\n",
    "        return super().validate_configuration(configuration)\n",
    "\n",
    "    def _validate(self, configuration, metrics, runtime_configuration=None, execution_engine=None):\n",
    "        df = execution_engine.get_domain_records(configuration.domain_kwargs)\n",
    "        colA = configuration.kwargs[\"column_A\"]\n",
    "        colB = configuration.kwargs[\"column_B\"]\n",
    "\n",
    "        result_series = (df[colA] + df[colB]) > 0\n",
    "        unexpected_indices = (~result_series).to_numpy().nonzero()[0].tolist()\n",
    "        return {\n",
    "            \"success\": result_series.all(),\n",
    "            \"result\": {\"unexpected_index_list\": unexpected_indices}\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f4709bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from great_expectations.core import ExpectationSuite, ExpectationConfiguration\n",
    "import re\n",
    "\n",
    "\n",
    "def build_raw_data_expectation_suite(suite_name: str = \"raw_data_suite\") -> ExpectationSuite:\n",
    "    \"\"\"\n",
    "    Builds an ExpectationSuite for raw hotel booking data using schema-driven and logical validations.\n",
    "\n",
    "    Returns:\n",
    "        ExpectationSuite: A suite of expectations for the raw data.\n",
    "    \"\"\"\n",
    "    suite = ExpectationSuite(expectation_suite_name=suite_name)\n",
    "\n",
    "    # Column type expectations\n",
    "    expected_types = {\n",
    "        \"Booking_ID\": \"object\",\n",
    "        \"number of adults\": \"int64\",\n",
    "        \"number of children\": \"int64\",\n",
    "        \"number of weekend nights\": \"int64\",\n",
    "        \"number of week nights\": \"int64\",\n",
    "        \"type of meal\": \"object\",\n",
    "        \"car parking space\": \"int64\",\n",
    "        \"room type\": \"object\",\n",
    "        \"lead time\": \"int64\",\n",
    "        \"market segment type\": \"object\",\n",
    "        \"repeated\": \"int64\",\n",
    "        \"P-C\": \"int64\",\n",
    "        \"P-not-C\": \"int64\",\n",
    "        \"average price\": \"float64\",\n",
    "        \"special requests\": \"int64\",\n",
    "        \"date of reservation\": \"object\",\n",
    "        \"booking status\": \"object\"\n",
    "    }\n",
    "\n",
    "    for column, dtype in expected_types.items():\n",
    "        suite.add_expectation(\n",
    "            ExpectationConfiguration(\n",
    "                expectation_type=\"expect_column_values_to_be_of_type\",\n",
    "                kwargs={\"column\": column, \"type_\": dtype}\n",
    "            )\n",
    "        )\n",
    "\n",
    "    # Non-null expectations\n",
    "    for column in expected_types.keys():\n",
    "        suite.add_expectation(\n",
    "            ExpectationConfiguration(\n",
    "                expectation_type=\"expect_column_values_to_not_be_null\",\n",
    "                kwargs={\"column\": column}\n",
    "            )\n",
    "        )\n",
    "\n",
    "    # No negative values in numeric columns\n",
    "    non_negative_cols = [\n",
    "        \"number of adults\", \"number of children\", \"number of weekend nights\",\n",
    "        \"number of week nights\", \"car parking space\", \"lead time\",\n",
    "        \"P-C\", \"P-not-C\", \"average price\", \"special requests\"\n",
    "    ]\n",
    "    for column in non_negative_cols:\n",
    "        suite.add_expectation(\n",
    "            ExpectationConfiguration(\n",
    "                expectation_type=\"expect_column_min_to_be_between\",\n",
    "                kwargs={\"column\": column, \"min_value\": 0, \"strict_min\": False}\n",
    "            )\n",
    "        )\n",
    "    ## Add the new custom expectations:\n",
    "    suite.add_expectation(\n",
    "        ExpectationConfiguration(\n",
    "            expectation_type=\"expect_column_pair_sum_greater_than_zero\",\n",
    "            kwargs={\"column_A\": \"number of adults\", \"column_B\": \"number of children\"}\n",
    "        )\n",
    "    )\n",
    "    suite.add_expectation(\n",
    "        ExpectationConfiguration(\n",
    "            expectation_type=\"expect_column_pair_sum_greater_than_zero\",\n",
    "            kwargs={\"column_A\": \"number of weekend nights\", \"column_B\": \"number of week nights\"}\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Format of date of reservation string can be potentially parsed as date (no validity check yet)\n",
    "    suite.add_expectation(\n",
    "        ExpectationConfiguration(\n",
    "            expectation_type=\"expect_column_values_to_match_regex\",\n",
    "            kwargs={\n",
    "                \"column\": \"date of reservation\",\n",
    "                \"regex\": r\"^(\\d{1,2}/\\d{1,2}/\\d{4}|\\d{4}-\\d{1,2}-\\d{1,2})\"\n",
    "            }\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Booking status should be either 'Canceled' or 'Not_Canceled'\n",
    "    suite.add_expectation(\n",
    "        ExpectationConfiguration(\n",
    "            expectation_type=\"expect_column_distinct_values_to_be_in_set\",\n",
    "            kwargs={\n",
    "                \"column\": \"booking status\",\n",
    "                \"value_set\": [\"Canceled\", \"Not_Canceled\"]\n",
    "            }\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Car parking space should be 0 or 1 (to be transformed into categorical)\n",
    "    suite.add_expectation(\n",
    "        ExpectationConfiguration(\n",
    "            expectation_type=\"expect_column_distinct_values_to_be_in_set\",\n",
    "            kwargs={\n",
    "                \"column\": \"car parking space\",\n",
    "                \"value_set\": [0, 1]\n",
    "            }\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Repeated should be 0 or 1 (to be transformed into categorical)\n",
    "    suite.add_expectation(\n",
    "        ExpectationConfiguration(\n",
    "            expectation_type=\"expect_column_distinct_values_to_be_in_set\",\n",
    "            kwargs={\n",
    "                \"column\": \"repeated\",\n",
    "                \"value_set\": [0, 1]\n",
    "            }\n",
    "        )\n",
    "    )\n",
    "\n",
    "    return suite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "38d5cd67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation success: False\n",
      "\n",
      "Expectation: expect_column_values_to_be_of_type\n",
      "✅ Success: []\n",
      "\n",
      "Expectation: expect_column_values_to_not_be_null\n",
      "✅ Success: []\n",
      "\n",
      "Expectation: expect_column_values_to_be_of_type\n",
      "✅ Success: []\n",
      "\n",
      "Expectation: expect_column_values_to_not_be_null\n",
      "✅ Success: []\n",
      "\n",
      "Expectation: expect_column_min_to_be_between\n",
      "✅ Success: []\n",
      "\n",
      "Expectation: expect_column_values_to_be_of_type\n",
      "✅ Success: []\n",
      "\n",
      "Expectation: expect_column_values_to_not_be_null\n",
      "✅ Success: []\n",
      "\n",
      "Expectation: expect_column_min_to_be_between\n",
      "✅ Success: []\n",
      "\n",
      "Expectation: expect_column_values_to_be_of_type\n",
      "✅ Success: []\n",
      "\n",
      "Expectation: expect_column_values_to_not_be_null\n",
      "✅ Success: []\n",
      "\n",
      "Expectation: expect_column_min_to_be_between\n",
      "✅ Success: []\n",
      "\n",
      "Expectation: expect_column_values_to_be_of_type\n",
      "✅ Success: []\n",
      "\n",
      "Expectation: expect_column_values_to_not_be_null\n",
      "✅ Success: []\n",
      "\n",
      "Expectation: expect_column_min_to_be_between\n",
      "✅ Success: []\n",
      "\n",
      "Expectation: expect_column_values_to_be_of_type\n",
      "✅ Success: []\n",
      "\n",
      "Expectation: expect_column_values_to_not_be_null\n",
      "✅ Success: []\n",
      "\n",
      "Expectation: expect_column_values_to_be_of_type\n",
      "✅ Success: []\n",
      "\n",
      "Expectation: expect_column_values_to_not_be_null\n",
      "✅ Success: []\n",
      "\n",
      "Expectation: expect_column_min_to_be_between\n",
      "✅ Success: []\n",
      "\n",
      "Expectation: expect_column_distinct_values_to_be_in_set\n",
      "✅ Success: []\n",
      "\n",
      "Expectation: expect_column_values_to_be_of_type\n",
      "✅ Success: []\n",
      "\n",
      "Expectation: expect_column_values_to_not_be_null\n",
      "✅ Success: []\n",
      "\n",
      "Expectation: expect_column_values_to_be_of_type\n",
      "✅ Success: []\n",
      "\n",
      "Expectation: expect_column_values_to_not_be_null\n",
      "✅ Success: []\n",
      "\n",
      "Expectation: expect_column_min_to_be_between\n",
      "✅ Success: []\n",
      "\n",
      "Expectation: expect_column_values_to_be_of_type\n",
      "✅ Success: []\n",
      "\n",
      "Expectation: expect_column_values_to_not_be_null\n",
      "✅ Success: []\n",
      "\n",
      "Expectation: expect_column_values_to_be_of_type\n",
      "✅ Success: []\n",
      "\n",
      "Expectation: expect_column_values_to_not_be_null\n",
      "✅ Success: []\n",
      "\n",
      "Expectation: expect_column_distinct_values_to_be_in_set\n",
      "✅ Success: []\n",
      "\n",
      "Expectation: expect_column_values_to_be_of_type\n",
      "✅ Success: []\n",
      "\n",
      "Expectation: expect_column_values_to_not_be_null\n",
      "✅ Success: []\n",
      "\n",
      "Expectation: expect_column_min_to_be_between\n",
      "✅ Success: []\n",
      "\n",
      "Expectation: expect_column_values_to_be_of_type\n",
      "✅ Success: []\n",
      "\n",
      "Expectation: expect_column_values_to_not_be_null\n",
      "✅ Success: []\n",
      "\n",
      "Expectation: expect_column_min_to_be_between\n",
      "✅ Success: []\n",
      "\n",
      "Expectation: expect_column_values_to_be_of_type\n",
      "✅ Success: []\n",
      "\n",
      "Expectation: expect_column_values_to_not_be_null\n",
      "✅ Success: []\n",
      "\n",
      "Expectation: expect_column_min_to_be_between\n",
      "✅ Success: []\n",
      "\n",
      "Expectation: expect_column_values_to_be_of_type\n",
      "✅ Success: []\n",
      "\n",
      "Expectation: expect_column_values_to_not_be_null\n",
      "✅ Success: []\n",
      "\n",
      "Expectation: expect_column_min_to_be_between\n",
      "✅ Success: []\n",
      "\n",
      "Expectation: expect_column_values_to_be_of_type\n",
      "✅ Success: []\n",
      "\n",
      "Expectation: expect_column_values_to_not_be_null\n",
      "✅ Success: []\n",
      "\n",
      "Expectation: expect_column_values_to_match_regex\n",
      "✅ Success: []\n",
      "\n",
      "Expectation: expect_column_values_to_be_of_type\n",
      "✅ Success: []\n",
      "\n",
      "Expectation: expect_column_values_to_not_be_null\n",
      "✅ Success: []\n",
      "\n",
      "Expectation: expect_column_distinct_values_to_be_in_set\n",
      "✅ Success: []\n",
      "\n",
      "Expectation: expect_column_pair_sum_greater_than_zero\n",
      "❌ Failed: []\n",
      "\n",
      "Expectation: expect_column_pair_sum_greater_than_zero\n",
      "❌ Failed: []\n"
     ]
    }
   ],
   "source": [
    "from great_expectations.checkpoint.types.checkpoint_result import CheckpointResult\n",
    "from great_expectations.core.batch import BatchRequest\n",
    "from great_expectations.validator.validator import Validator\n",
    "from great_expectations.dataset import PandasDataset\n",
    "\n",
    "# Assume df_raw is your raw dataset (a pandas DataFrame)\n",
    "df_raw_ge = gx.dataset.PandasDataset(df_raw)\n",
    "\n",
    "# Build the suite\n",
    "suite = build_raw_data_expectation_suite()\n",
    "\n",
    "# Validate\n",
    "results = df_raw_ge.validate(expectation_suite=suite)\n",
    "\n",
    "# Print summary\n",
    "print(\"Validation success:\", results[\"success\"])\n",
    "for res in results[\"results\"]:\n",
    "    print(f\"\\nExpectation: {res['expectation_config']['expectation_type']}\")\n",
    "    print(\"✅ Success:\" if res[\"success\"] else \"❌ Failed:\", res[\"result\"].get(\"unexpected_index_list\", []))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "48d16961",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation success: False\n",
      "\n",
      "Expectation: expect_column_values_to_be_of_type\n",
      "✅ Passed\n",
      "\n",
      "Expectation: expect_column_values_to_not_be_null\n",
      "✅ Passed\n",
      "\n",
      "Expectation: expect_column_values_to_be_of_type\n",
      "✅ Passed\n",
      "\n",
      "Expectation: expect_column_values_to_not_be_null\n",
      "✅ Passed\n",
      "\n",
      "Expectation: expect_column_min_to_be_between\n",
      "✅ Passed\n",
      "\n",
      "Expectation: expect_column_values_to_be_of_type\n",
      "✅ Passed\n",
      "\n",
      "Expectation: expect_column_values_to_not_be_null\n",
      "✅ Passed\n",
      "\n",
      "Expectation: expect_column_min_to_be_between\n",
      "✅ Passed\n",
      "\n",
      "Expectation: expect_column_values_to_be_of_type\n",
      "✅ Passed\n",
      "\n",
      "Expectation: expect_column_values_to_not_be_null\n",
      "✅ Passed\n",
      "\n",
      "Expectation: expect_column_min_to_be_between\n",
      "✅ Passed\n",
      "\n",
      "Expectation: expect_column_values_to_be_of_type\n",
      "✅ Passed\n",
      "\n",
      "Expectation: expect_column_values_to_not_be_null\n",
      "✅ Passed\n",
      "\n",
      "Expectation: expect_column_min_to_be_between\n",
      "✅ Passed\n",
      "\n",
      "Expectation: expect_column_values_to_be_of_type\n",
      "✅ Passed\n",
      "\n",
      "Expectation: expect_column_values_to_not_be_null\n",
      "✅ Passed\n",
      "\n",
      "Expectation: expect_column_values_to_be_of_type\n",
      "✅ Passed\n",
      "\n",
      "Expectation: expect_column_values_to_not_be_null\n",
      "✅ Passed\n",
      "\n",
      "Expectation: expect_column_min_to_be_between\n",
      "✅ Passed\n",
      "\n",
      "Expectation: expect_column_distinct_values_to_be_in_set\n",
      "✅ Passed\n",
      "\n",
      "Expectation: expect_column_values_to_be_of_type\n",
      "✅ Passed\n",
      "\n",
      "Expectation: expect_column_values_to_not_be_null\n",
      "✅ Passed\n",
      "\n",
      "Expectation: expect_column_values_to_be_of_type\n",
      "✅ Passed\n",
      "\n",
      "Expectation: expect_column_values_to_not_be_null\n",
      "✅ Passed\n",
      "\n",
      "Expectation: expect_column_min_to_be_between\n",
      "✅ Passed\n",
      "\n",
      "Expectation: expect_column_values_to_be_of_type\n",
      "✅ Passed\n",
      "\n",
      "Expectation: expect_column_values_to_not_be_null\n",
      "✅ Passed\n",
      "\n",
      "Expectation: expect_column_values_to_be_of_type\n",
      "✅ Passed\n",
      "\n",
      "Expectation: expect_column_values_to_not_be_null\n",
      "✅ Passed\n",
      "\n",
      "Expectation: expect_column_distinct_values_to_be_in_set\n",
      "✅ Passed\n",
      "\n",
      "Expectation: expect_column_values_to_be_of_type\n",
      "✅ Passed\n",
      "\n",
      "Expectation: expect_column_values_to_not_be_null\n",
      "✅ Passed\n",
      "\n",
      "Expectation: expect_column_min_to_be_between\n",
      "✅ Passed\n",
      "\n",
      "Expectation: expect_column_values_to_be_of_type\n",
      "✅ Passed\n",
      "\n",
      "Expectation: expect_column_values_to_not_be_null\n",
      "✅ Passed\n",
      "\n",
      "Expectation: expect_column_min_to_be_between\n",
      "✅ Passed\n",
      "\n",
      "Expectation: expect_column_values_to_be_of_type\n",
      "✅ Passed\n",
      "\n",
      "Expectation: expect_column_values_to_not_be_null\n",
      "✅ Passed\n",
      "\n",
      "Expectation: expect_column_min_to_be_between\n",
      "✅ Passed\n",
      "\n",
      "Expectation: expect_column_values_to_be_of_type\n",
      "✅ Passed\n",
      "\n",
      "Expectation: expect_column_values_to_not_be_null\n",
      "✅ Passed\n",
      "\n",
      "Expectation: expect_column_min_to_be_between\n",
      "✅ Passed\n",
      "\n",
      "Expectation: expect_column_values_to_be_of_type\n",
      "✅ Passed\n",
      "\n",
      "Expectation: expect_column_values_to_not_be_null\n",
      "✅ Passed\n",
      "\n",
      "Expectation: expect_column_values_to_match_regex\n",
      "✅ Passed\n",
      "\n",
      "Expectation: expect_column_values_to_be_of_type\n",
      "✅ Passed\n",
      "\n",
      "Expectation: expect_column_values_to_not_be_null\n",
      "✅ Passed\n",
      "\n",
      "Expectation: expect_column_distinct_values_to_be_in_set\n",
      "✅ Passed\n",
      "\n",
      "Expectation: expect_column_pair_sum_greater_than_zero\n",
      "❌ Failed at rows: []\n",
      "\n",
      "Expectation: expect_column_pair_sum_greater_than_zero\n",
      "❌ Failed at rows: []\n"
     ]
    }
   ],
   "source": [
    "import great_expectations as gx\n",
    "from great_expectations.core import ExpectationSuite\n",
    "\n",
    "# Build your suite\n",
    "suite = build_raw_data_expectation_suite()\n",
    "\n",
    "# Wrap your DataFrame for validation\n",
    "df_ge = gx.dataset.PandasDataset(df_raw)\n",
    "\n",
    "# Validate df directly with the suite\n",
    "results = df_ge.validate(expectation_suite=suite)\n",
    "\n",
    "# Print summary with details on failures\n",
    "print(\"Validation success:\", results[\"success\"])\n",
    "for res in results[\"results\"]:\n",
    "    exp_type = res[\"expectation_config\"][\"expectation_type\"]\n",
    "    success = res[\"success\"]\n",
    "    unexpected = res[\"result\"].get(\"unexpected_index_list\", [])\n",
    "    print(f\"\\nExpectation: {exp_type}\")\n",
    "    print(\"✅ Passed\" if success else f\"❌ Failed at rows: {unexpected}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1d8d8a1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Full result for debugging ---\n",
      "{'observed_value': 'object_'}\n",
      "\n",
      "--- Full result for debugging ---\n",
      "{'element_count': 36285,\n",
      " 'partial_unexpected_list': [],\n",
      " 'unexpected_count': 0,\n",
      " 'unexpected_percent': 0.0,\n",
      " 'unexpected_percent_total': 0.0}\n",
      "\n",
      "--- Full result for debugging ---\n",
      "{'observed_value': 'int64'}\n",
      "\n",
      "--- Full result for debugging ---\n",
      "{'element_count': 36285,\n",
      " 'partial_unexpected_list': [],\n",
      " 'unexpected_count': 0,\n",
      " 'unexpected_percent': 0.0,\n",
      " 'unexpected_percent_total': 0.0}\n",
      "\n",
      "--- Full result for debugging ---\n",
      "{'element_count': 36285,\n",
      " 'missing_count': None,\n",
      " 'missing_percent': None,\n",
      " 'observed_value': 0}\n",
      "\n",
      "--- Full result for debugging ---\n",
      "{'observed_value': 'int64'}\n",
      "\n",
      "--- Full result for debugging ---\n",
      "{'element_count': 36285,\n",
      " 'partial_unexpected_list': [],\n",
      " 'unexpected_count': 0,\n",
      " 'unexpected_percent': 0.0,\n",
      " 'unexpected_percent_total': 0.0}\n",
      "\n",
      "--- Full result for debugging ---\n",
      "{'element_count': 36285,\n",
      " 'missing_count': None,\n",
      " 'missing_percent': None,\n",
      " 'observed_value': 0}\n",
      "\n",
      "--- Full result for debugging ---\n",
      "{'observed_value': 'int64'}\n",
      "\n",
      "--- Full result for debugging ---\n",
      "{'element_count': 36285,\n",
      " 'partial_unexpected_list': [],\n",
      " 'unexpected_count': 0,\n",
      " 'unexpected_percent': 0.0,\n",
      " 'unexpected_percent_total': 0.0}\n",
      "\n",
      "--- Full result for debugging ---\n",
      "{'element_count': 36285,\n",
      " 'missing_count': None,\n",
      " 'missing_percent': None,\n",
      " 'observed_value': 0}\n",
      "\n",
      "--- Full result for debugging ---\n",
      "{'observed_value': 'int64'}\n",
      "\n",
      "--- Full result for debugging ---\n",
      "{'element_count': 36285,\n",
      " 'partial_unexpected_list': [],\n",
      " 'unexpected_count': 0,\n",
      " 'unexpected_percent': 0.0,\n",
      " 'unexpected_percent_total': 0.0}\n",
      "\n",
      "--- Full result for debugging ---\n",
      "{'element_count': 36285,\n",
      " 'missing_count': None,\n",
      " 'missing_percent': None,\n",
      " 'observed_value': 0}\n",
      "\n",
      "--- Full result for debugging ---\n",
      "{'observed_value': 'object_'}\n",
      "\n",
      "--- Full result for debugging ---\n",
      "{'element_count': 36285,\n",
      " 'partial_unexpected_list': [],\n",
      " 'unexpected_count': 0,\n",
      " 'unexpected_percent': 0.0,\n",
      " 'unexpected_percent_total': 0.0}\n",
      "\n",
      "--- Full result for debugging ---\n",
      "{'observed_value': 'int64'}\n",
      "\n",
      "--- Full result for debugging ---\n",
      "{'element_count': 36285,\n",
      " 'partial_unexpected_list': [],\n",
      " 'unexpected_count': 0,\n",
      " 'unexpected_percent': 0.0,\n",
      " 'unexpected_percent_total': 0.0}\n",
      "\n",
      "--- Full result for debugging ---\n",
      "{'element_count': 36285,\n",
      " 'missing_count': None,\n",
      " 'missing_percent': None,\n",
      " 'observed_value': 0}\n",
      "\n",
      "--- Full result for debugging ---\n",
      "{'element_count': 36285,\n",
      " 'missing_count': None,\n",
      " 'missing_percent': None,\n",
      " 'observed_value': [0, 1]}\n",
      "\n",
      "--- Full result for debugging ---\n",
      "{'observed_value': 'object_'}\n",
      "\n",
      "--- Full result for debugging ---\n",
      "{'element_count': 36285,\n",
      " 'partial_unexpected_list': [],\n",
      " 'unexpected_count': 0,\n",
      " 'unexpected_percent': 0.0,\n",
      " 'unexpected_percent_total': 0.0}\n",
      "\n",
      "--- Full result for debugging ---\n",
      "{'observed_value': 'int64'}\n",
      "\n",
      "--- Full result for debugging ---\n",
      "{'element_count': 36285,\n",
      " 'partial_unexpected_list': [],\n",
      " 'unexpected_count': 0,\n",
      " 'unexpected_percent': 0.0,\n",
      " 'unexpected_percent_total': 0.0}\n",
      "\n",
      "--- Full result for debugging ---\n",
      "{'element_count': 36285,\n",
      " 'missing_count': None,\n",
      " 'missing_percent': None,\n",
      " 'observed_value': 0}\n",
      "\n",
      "--- Full result for debugging ---\n",
      "{'observed_value': 'object_'}\n",
      "\n",
      "--- Full result for debugging ---\n",
      "{'element_count': 36285,\n",
      " 'partial_unexpected_list': [],\n",
      " 'unexpected_count': 0,\n",
      " 'unexpected_percent': 0.0,\n",
      " 'unexpected_percent_total': 0.0}\n",
      "\n",
      "--- Full result for debugging ---\n",
      "{'observed_value': 'int64'}\n",
      "\n",
      "--- Full result for debugging ---\n",
      "{'element_count': 36285,\n",
      " 'partial_unexpected_list': [],\n",
      " 'unexpected_count': 0,\n",
      " 'unexpected_percent': 0.0,\n",
      " 'unexpected_percent_total': 0.0}\n",
      "\n",
      "--- Full result for debugging ---\n",
      "{'element_count': 36285,\n",
      " 'missing_count': None,\n",
      " 'missing_percent': None,\n",
      " 'observed_value': [0, 1]}\n",
      "\n",
      "--- Full result for debugging ---\n",
      "{'observed_value': 'int64'}\n",
      "\n",
      "--- Full result for debugging ---\n",
      "{'element_count': 36285,\n",
      " 'partial_unexpected_list': [],\n",
      " 'unexpected_count': 0,\n",
      " 'unexpected_percent': 0.0,\n",
      " 'unexpected_percent_total': 0.0}\n",
      "\n",
      "--- Full result for debugging ---\n",
      "{'element_count': 36285,\n",
      " 'missing_count': None,\n",
      " 'missing_percent': None,\n",
      " 'observed_value': 0}\n",
      "\n",
      "--- Full result for debugging ---\n",
      "{'observed_value': 'int64'}\n",
      "\n",
      "--- Full result for debugging ---\n",
      "{'element_count': 36285,\n",
      " 'partial_unexpected_list': [],\n",
      " 'unexpected_count': 0,\n",
      " 'unexpected_percent': 0.0,\n",
      " 'unexpected_percent_total': 0.0}\n",
      "\n",
      "--- Full result for debugging ---\n",
      "{'element_count': 36285,\n",
      " 'missing_count': None,\n",
      " 'missing_percent': None,\n",
      " 'observed_value': 0}\n",
      "\n",
      "--- Full result for debugging ---\n",
      "{'observed_value': 'float64'}\n",
      "\n",
      "--- Full result for debugging ---\n",
      "{'element_count': 36285,\n",
      " 'partial_unexpected_list': [],\n",
      " 'unexpected_count': 0,\n",
      " 'unexpected_percent': 0.0,\n",
      " 'unexpected_percent_total': 0.0}\n",
      "\n",
      "--- Full result for debugging ---\n",
      "{'element_count': 36285,\n",
      " 'missing_count': None,\n",
      " 'missing_percent': None,\n",
      " 'observed_value': 0.0}\n",
      "\n",
      "--- Full result for debugging ---\n",
      "{'observed_value': 'int64'}\n",
      "\n",
      "--- Full result for debugging ---\n",
      "{'element_count': 36285,\n",
      " 'partial_unexpected_list': [],\n",
      " 'unexpected_count': 0,\n",
      " 'unexpected_percent': 0.0,\n",
      " 'unexpected_percent_total': 0.0}\n",
      "\n",
      "--- Full result for debugging ---\n",
      "{'element_count': 36285,\n",
      " 'missing_count': None,\n",
      " 'missing_percent': None,\n",
      " 'observed_value': 0}\n",
      "\n",
      "--- Full result for debugging ---\n",
      "{'observed_value': 'object_'}\n",
      "\n",
      "--- Full result for debugging ---\n",
      "{'element_count': 36285,\n",
      " 'partial_unexpected_list': [],\n",
      " 'unexpected_count': 0,\n",
      " 'unexpected_percent': 0.0,\n",
      " 'unexpected_percent_total': 0.0}\n",
      "\n",
      "--- Full result for debugging ---\n",
      "{'element_count': 36285,\n",
      " 'missing_count': 0,\n",
      " 'missing_percent': 0.0,\n",
      " 'partial_unexpected_list': [],\n",
      " 'unexpected_count': 0,\n",
      " 'unexpected_percent': 0.0,\n",
      " 'unexpected_percent_nonmissing': 0.0,\n",
      " 'unexpected_percent_total': 0.0}\n",
      "\n",
      "--- Full result for debugging ---\n",
      "{'observed_value': 'object_'}\n",
      "\n",
      "--- Full result for debugging ---\n",
      "{'element_count': 36285,\n",
      " 'partial_unexpected_list': [],\n",
      " 'unexpected_count': 0,\n",
      " 'unexpected_percent': 0.0,\n",
      " 'unexpected_percent_total': 0.0}\n",
      "\n",
      "--- Full result for debugging ---\n",
      "{'element_count': 36285,\n",
      " 'missing_count': None,\n",
      " 'missing_percent': None,\n",
      " 'observed_value': ['Canceled', 'Not_Canceled']}\n",
      "\n",
      "--- Full result for debugging ---\n",
      "{}\n",
      "\n",
      "--- Full result for debugging ---\n",
      "{}\n"
     ]
    }
   ],
   "source": [
    "# debugging custom expectations\n",
    "import pprint\n",
    "\n",
    "for res in results[\"results\"]:\n",
    "    print(\"\\n--- Full result for debugging ---\")\n",
    "    pprint.pprint(res[\"result\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "850d95f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print((df_raw[\"number of week nights\"] + df_raw[\"number of weekend nights\"]).min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f448485f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Booking_ID</th>\n",
       "      <th>number of adults</th>\n",
       "      <th>number of children</th>\n",
       "      <th>number of weekend nights</th>\n",
       "      <th>number of week nights</th>\n",
       "      <th>type of meal</th>\n",
       "      <th>car parking space</th>\n",
       "      <th>room type</th>\n",
       "      <th>lead time</th>\n",
       "      <th>market segment type</th>\n",
       "      <th>repeated</th>\n",
       "      <th>P-C</th>\n",
       "      <th>P-not-C</th>\n",
       "      <th>average price</th>\n",
       "      <th>special requests</th>\n",
       "      <th>date of reservation</th>\n",
       "      <th>booking status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>INN00210</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Meal Plan 1</td>\n",
       "      <td>0</td>\n",
       "      <td>Room_Type 1</td>\n",
       "      <td>4</td>\n",
       "      <td>Complementary</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2/27/2018</td>\n",
       "      <td>Not_Canceled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1158</th>\n",
       "      <td>INN01159</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Meal Plan 1</td>\n",
       "      <td>0</td>\n",
       "      <td>Room_Type 1</td>\n",
       "      <td>145</td>\n",
       "      <td>Online</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>7/5/2018</td>\n",
       "      <td>Not_Canceled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1403</th>\n",
       "      <td>INN01404</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Meal Plan 1</td>\n",
       "      <td>0</td>\n",
       "      <td>Room_Type 4</td>\n",
       "      <td>57</td>\n",
       "      <td>Online</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>4/1/2018</td>\n",
       "      <td>Not_Canceled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1907</th>\n",
       "      <td>INN01908</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Meal Plan 2</td>\n",
       "      <td>0</td>\n",
       "      <td>Room_Type 1</td>\n",
       "      <td>247</td>\n",
       "      <td>Online</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>6/6/2018</td>\n",
       "      <td>Not_Canceled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1986</th>\n",
       "      <td>INN01987</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Meal Plan 1</td>\n",
       "      <td>0</td>\n",
       "      <td>Room_Type 1</td>\n",
       "      <td>43</td>\n",
       "      <td>Online</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>10/17/2017</td>\n",
       "      <td>Not_Canceled</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Booking_ID  number of adults  number of children  \\\n",
       "209    INN00210                 1                   0   \n",
       "1158   INN01159                 2                   0   \n",
       "1403   INN01404                 3                   0   \n",
       "1907   INN01908                 2                   0   \n",
       "1986   INN01987                 2                   0   \n",
       "\n",
       "      number of weekend nights  number of week nights type of meal  \\\n",
       "209                          0                      0  Meal Plan 1   \n",
       "1158                         0                      0  Meal Plan 1   \n",
       "1403                         0                      0  Meal Plan 1   \n",
       "1907                         0                      0  Meal Plan 2   \n",
       "1986                         0                      0  Meal Plan 1   \n",
       "\n",
       "      car parking space    room type  lead time market segment type  repeated  \\\n",
       "209                   0  Room_Type 1          4       Complementary         0   \n",
       "1158                  0  Room_Type 1        145              Online         0   \n",
       "1403                  0  Room_Type 4         57              Online         0   \n",
       "1907                  0  Room_Type 1        247              Online         0   \n",
       "1986                  0  Room_Type 1         43              Online         0   \n",
       "\n",
       "      P-C  P-not-C  average price  special requests date of reservation  \\\n",
       "209     0        0            0.0                 1           2/27/2018   \n",
       "1158    0        0            0.0                 1            7/5/2018   \n",
       "1403    0        0            0.0                 2            4/1/2018   \n",
       "1907    0        0            0.0                 1            6/6/2018   \n",
       "1986    0        0            0.0                 1          10/17/2017   \n",
       "\n",
       "     booking status  \n",
       "209    Not_Canceled  \n",
       "1158   Not_Canceled  \n",
       "1403   Not_Canceled  \n",
       "1907   Not_Canceled  \n",
       "1986   Not_Canceled  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df = df_raw[(df_raw['number of week nights'] ==0 ) & (df_raw['number of weekend nights'] ==0)]\n",
    "filtered_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b29eaba2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(78, 17)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1057fec2",
   "metadata": {},
   "source": [
    "78 bookings are for 0 week nights and 0 weekend nights - invalid bookings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd9f20d",
   "metadata": {},
   "source": [
    "## Data Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8623cbb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(df, cutoff_date):\n",
    "    df = df.copy()\n",
    "\n",
    "    ref_data = df[df['date of reservation'] <= cutoff_date]\n",
    "    ana_data = df[df['date of reservation'] > cutoff_date]\n",
    "\n",
    "    return ref_data, ana_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e9c9e0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_data, ana_data = split_data(df_raw, \"9/19/2018\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3767c97f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33431, 17)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ref_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1a5ec354",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2854, 17)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ana_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf4962f",
   "metadata": {},
   "source": [
    "## Preprocessing Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ece8f8f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Dict, Tuple\n",
    "import pandas as pd\n",
    "\n",
    "def clean_data(\n",
    "    data: pd.DataFrame,\n",
    ") -> Tuple[pd.DataFrame, Dict, Dict]:    \n",
    "\n",
    "    df_transformed = data.copy()\n",
    "\n",
    "    # snake case names of columns\n",
    "    df_transformed.columns = df_transformed.columns.str.replace(' ', '_').str.lower()\n",
    "\n",
    "    # convert date of reservation to Datetime \n",
    "    df_transformed['date_of_reservation'] = pd.to_datetime(df_transformed['date_of_reservation'], errors='coerce')\n",
    "\n",
    "    # drop raws NaN values (including NaT with invalid dates)\n",
    "    df_transformed = df_transformed.dropna()\n",
    "\n",
    "    # cast repeated and car parking space as boolean\n",
    "    df_transformed[\"car_parking_space\"] = df_transformed[\"car_parking_space\"].astype(bool)\n",
    "    df_transformed[\"repeated\"] = df_transformed[\"repeated\"].astype(bool)\n",
    "\n",
    "    # drop invalid bookings with 0 sum of week and weekend nights\n",
    "    df_transformed = df_transformed[~((df_transformed['number_of_week_nights'] == 0) & (df_transformed['number_of_weekend_nights'] == 0))]\n",
    "\n",
    "    # remove outliers\n",
    "    for cols in [\"lead_time\"]:\n",
    "        Q1 = df_transformed[cols].quantile(0.25)\n",
    "        Q3 = df_transformed[cols].quantile(0.75)\n",
    "        IQR = Q3 - Q1     \n",
    "\n",
    "        filter = (df_transformed[cols] >= Q1 - 1.5 * IQR) & (df_transformed[cols] <= Q3 + 1.5 *IQR)\n",
    "        df_transformed = df_transformed.loc[filter]\n",
    "\n",
    "    describe_to_dict_verified = df_transformed.describe().to_dict()\n",
    "\n",
    "    return df_transformed, describe_to_dict_verified "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49cc9cee",
   "metadata": {},
   "source": [
    "## Test Preprocessing Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "abc1b942",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_clean_data_type(df):\n",
    "    #df = pd.read_csv(\"./tests/pipelines/sample/sample.csv\") \n",
    "    df_transformed, describe_to_dict_verified  = clean_data(df)\n",
    "    isinstance(describe_to_dict_verified, dict)\n",
    "\n",
    "def test_clean_data_null(df): #e.g. if there are still null values after data cleaning\n",
    "    #df = pd.read_csv(\"./tests/pipelines/sample/sample.csv\") \n",
    "    df_transformed, describe_to_dict_verified = clean_data(df)\n",
    "    assert [col for col in df_transformed.columns if df_transformed[col].isnull().any()] == []\n",
    "\n",
    "def test_clean_data_valid_bookings(df):\n",
    "    #df = pd.read_csv(\"./tests/pipelines/sample/sample.csv\") \n",
    "    df_transformed, describe_to_dict_verified  = clean_data(df)\n",
    "    assert not ((df_transformed[\"number_of_week_nights\"] == 0) & (df_transformed[\"number_of_weekend_nights\"] == 0)).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "71124b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_clean_data_type(ref_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4e6187ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_clean_data_null(ref_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c7727a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_clean_data_valid_bookings(ref_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26bce006",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "\n",
    "We want to create a new feature: season. Based on the date of reservation and lead time, we can establish the first day of stay. Assume stay in June, July, August and December - high season, other months - low season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "37454275",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder , LabelEncoder\n",
    "\n",
    "def add_season(data: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = data.copy()\n",
    "    \n",
    "    #new season feature\n",
    "    df['season'] = pd.to_datetime(df['date_of_reservation']) + pd.to_timedelta(df['lead_time'], unit='d')\n",
    "    df['season'] = df['season'].dt.month.apply(lambda m: 'high' if m in [6,7,8,12] else 'low')\n",
    "\n",
    "    return df\n",
    "\n",
    "def feature_engineer( data: pd.DataFrame, OH_encoder) -> pd.DataFrame:\n",
    "    df = data.copy()\n",
    "\n",
    "\n",
    "    numerical_features = df.select_dtypes(exclude=['object','string','category']).columns.tolist()\n",
    "    categorical_features = df.select_dtypes(include=['object','string','category']).columns.tolist()\n",
    "\n",
    "    OH_cols= pd.DataFrame(OH_encoder.transform(df[categorical_features]))\n",
    "\n",
    "    # Adding column names to the encoded data set.\n",
    "    OH_cols.columns = OH_encoder.get_feature_names_out(categorical_features)\n",
    "\n",
    "    # One-hot encoding removed index; put it back\n",
    "    OH_cols.index = df.index\n",
    "\n",
    "    # Remove categorical columns (will replace with one-hot encoding)\n",
    "    num_df = df.drop(categorical_features, axis=1)\n",
    "\n",
    "    # Add one-hot encoded columns to numerical features\n",
    "    df_final = pd.concat([num_df, OH_cols], axis=1)\n",
    "\n",
    "    return df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "421e3a2f",
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 7.67 GiB for an array with shape (32076, 32096) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m OH_encoder \u001b[38;5;241m=\u001b[39m OneHotEncoder(handle_unknown\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m'\u001b[39m, sparse_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m      7\u001b[0m OH_encoder\u001b[38;5;241m.\u001b[39mfit(df_transformed[categorical_cols])\n\u001b[1;32m----> 9\u001b[0m df_final \u001b[38;5;241m=\u001b[39m \u001b[43mfeature_engineer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_transformed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mOH_encoder\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m df_final\u001b[38;5;241m.\u001b[39mhead()\n",
      "Cell \u001b[1;32mIn[26], line 19\u001b[0m, in \u001b[0;36mfeature_engineer\u001b[1;34m(data, OH_encoder)\u001b[0m\n\u001b[0;32m     16\u001b[0m numerical_features \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mselect_dtypes(exclude\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mobject\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstring\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategory\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[0;32m     17\u001b[0m categorical_features \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mselect_dtypes(include\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mobject\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstring\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategory\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[1;32m---> 19\u001b[0m OH_cols\u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(\u001b[43mOH_encoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcategorical_features\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# Adding column names to the encoded data set.\u001b[39;00m\n\u001b[0;32m     22\u001b[0m OH_cols\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;241m=\u001b[39m OH_encoder\u001b[38;5;241m.\u001b[39mget_feature_names_out(categorical_features)\n",
      "File \u001b[1;32mc:\\D\\4_FSS_2025_NOVA\\MLOps_project\\MLOps\\env_1\\Lib\\site-packages\\sklearn\\utils\\_set_output.py:319\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    318\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 319\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    320\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    321\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    322\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    323\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    324\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    325\u001b[0m         )\n",
      "File \u001b[1;32mc:\\D\\4_FSS_2025_NOVA\\MLOps_project\\MLOps\\env_1\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:1083\u001b[0m, in \u001b[0;36mOneHotEncoder.transform\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m   1077\u001b[0m out \u001b[38;5;241m=\u001b[39m sparse\u001b[38;5;241m.\u001b[39mcsr_matrix(\n\u001b[0;32m   1078\u001b[0m     (data, indices, indptr),\n\u001b[0;32m   1079\u001b[0m     shape\u001b[38;5;241m=\u001b[39m(n_samples, feature_indices[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]),\n\u001b[0;32m   1080\u001b[0m     dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtype,\n\u001b[0;32m   1081\u001b[0m )\n\u001b[0;32m   1082\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msparse_output:\n\u001b[1;32m-> 1083\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mout\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtoarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1084\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1085\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[1;32mc:\\D\\4_FSS_2025_NOVA\\MLOps_project\\MLOps\\env_1\\Lib\\site-packages\\scipy\\sparse\\_compressed.py:1170\u001b[0m, in \u001b[0;36m_cs_matrix.toarray\u001b[1;34m(self, order, out)\u001b[0m\n\u001b[0;32m   1168\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m order \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1169\u001b[0m     order \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_swap(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcf\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m-> 1170\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_toarray_args\u001b[49m\u001b[43m(\u001b[49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1171\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (out\u001b[38;5;241m.\u001b[39mflags\u001b[38;5;241m.\u001b[39mc_contiguous \u001b[38;5;129;01mor\u001b[39;00m out\u001b[38;5;241m.\u001b[39mflags\u001b[38;5;241m.\u001b[39mf_contiguous):\n\u001b[0;32m   1172\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOutput array must be C or F contiguous\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\D\\4_FSS_2025_NOVA\\MLOps_project\\MLOps\\env_1\\Lib\\site-packages\\scipy\\sparse\\_base.py:1367\u001b[0m, in \u001b[0;36m_spbase._process_toarray_args\u001b[1;34m(self, order, out)\u001b[0m\n\u001b[0;32m   1365\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m out\n\u001b[0;32m   1366\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1367\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzeros\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 7.67 GiB for an array with shape (32076, 32096) and data type float64"
     ]
    }
   ],
   "source": [
    "df_transformed, describe_to_dict_verified  = clean_data(ref_data)\n",
    "\n",
    "df_transformed = add_season(df_transformed)\n",
    "\n",
    "categorical_cols = df_transformed.select_dtypes(include=['object', 'string', 'category']).columns.tolist()\n",
    "OH_encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "OH_encoder.fit(df_transformed[categorical_cols])\n",
    "\n",
    "df_final = feature_engineer(df_transformed, OH_encoder)\n",
    "df_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8b854463",
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFittedError",
     "evalue": "This OneHotEncoder instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m df_transformed, describe_to_dict_verified  \u001b[38;5;241m=\u001b[39m clean_data(ref_data)\n\u001b[0;32m      3\u001b[0m ohe \u001b[38;5;241m=\u001b[39m OneHotEncoder(handle_unknown\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m, sparse_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m----> 5\u001b[0m df_final \u001b[38;5;241m=\u001b[39m \u001b[43mfeature_engineer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_transformed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mohe\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m df_final\u001b[38;5;241m.\u001b[39mhead()\n",
      "Cell \u001b[1;32mIn[22], line 14\u001b[0m, in \u001b[0;36mfeature_engineer\u001b[1;34m(data, OH_encoder)\u001b[0m\n\u001b[0;32m     11\u001b[0m numerical_features \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mselect_dtypes(exclude\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mobject\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstring\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategory\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[0;32m     12\u001b[0m categorical_features \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mselect_dtypes(include\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mobject\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstring\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategory\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[1;32m---> 14\u001b[0m OH_cols\u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(\u001b[43mOH_encoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcategorical_features\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Adding column names to the encoded data set.\u001b[39;00m\n\u001b[0;32m     17\u001b[0m OH_cols\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;241m=\u001b[39m OH_encoder\u001b[38;5;241m.\u001b[39mget_feature_names_out(categorical_features)\n",
      "File \u001b[1;32mc:\\D\\4_FSS_2025_NOVA\\MLOps_project\\MLOps\\env_1\\Lib\\site-packages\\sklearn\\utils\\_set_output.py:319\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    318\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 319\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    320\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    321\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    322\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    323\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    324\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    325\u001b[0m         )\n",
      "File \u001b[1;32mc:\\D\\4_FSS_2025_NOVA\\MLOps_project\\MLOps\\env_1\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:1023\u001b[0m, in \u001b[0;36mOneHotEncoder.transform\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m   1000\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mtransform\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[0;32m   1001\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1002\u001b[0m \u001b[38;5;124;03m    Transform X using one-hot encoding.\u001b[39;00m\n\u001b[0;32m   1003\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1021\u001b[0m \u001b[38;5;124;03m        returned.\u001b[39;00m\n\u001b[0;32m   1022\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1023\u001b[0m     \u001b[43mcheck_is_fitted\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1024\u001b[0m     transform_output \u001b[38;5;241m=\u001b[39m _get_output_config(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtransform\u001b[39m\u001b[38;5;124m\"\u001b[39m, estimator\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdense\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1025\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m transform_output \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdefault\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msparse_output:\n",
      "File \u001b[1;32mc:\\D\\4_FSS_2025_NOVA\\MLOps_project\\MLOps\\env_1\\Lib\\site-packages\\sklearn\\utils\\validation.py:1757\u001b[0m, in \u001b[0;36mcheck_is_fitted\u001b[1;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[0;32m   1754\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m   1756\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_fitted(estimator, attributes, all_or_any):\n\u001b[1;32m-> 1757\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NotFittedError(msg \u001b[38;5;241m%\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mtype\u001b[39m(estimator)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m})\n",
      "\u001b[1;31mNotFittedError\u001b[0m: This OneHotEncoder instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator."
     ]
    }
   ],
   "source": [
    "df_transformed, describe_to_dict_verified  = clean_data(ref_data)\n",
    "\n",
    "ohe = OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)\n",
    "\n",
    "df_final = feature_engineer(df_transformed, ohe)\n",
    "\n",
    "df_final.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "788f09ba",
   "metadata": {},
   "source": [
    "## Data Unit Tests After Preprocessing"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
