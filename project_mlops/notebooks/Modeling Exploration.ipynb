{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "155bb836-ebff-4ec8-80e3-bc9c8224b4fb",
   "metadata": {},
   "source": [
    "<div style=\"background-color: darkslategray; color: white; padding: 15px; border-radius: 8px;\">\n",
    "    <center><h3 style=\"font-family: Arial, sans-serif;\">MLOps Project - Modeling Exploration</h3></center>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "675a7717-7d3a-4cb3-85ac-6fb002569f37",
   "metadata": {},
   "source": [
    "**<h3>Table of Contents</h3>**\n",
    "* [1. Environment Setup](#1-environment-setup)\n",
    "    * [1.1 Import Libraries](#11-import-libraries)\n",
    "    * [1.2 Import Dataset](#12-import-dataset)\n",
    "* [2. Preprocessing](#2-preprocessing)\n",
    "    * [2.1 Train-Test Split](#21-train-test-split)\n",
    "    * [2.2 Scaling](#22-scaling)\n",
    "* [3. Modeling](#3-modeling)\n",
    "    * [3.1 Logistic Regression](#31-logistic-regression)\n",
    "    * [3.2 Decision Tree](#32-decision-tree)\n",
    "    * [3.3 Random Forest](#33-random-forest)\n",
    "    * [3.4 XGBoost](#34-xgboost)\n",
    "* [4. Wrap up for Pipelines](#4-wrap-up)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac8fab2-fcc5-4adb-8adf-ce9b175cfd34",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "# **1.** Environment Setup\n",
    "\n",
    "<div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "825fa64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc163456",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Asus\\\\Documents\\\\GitHub\\\\MLOps\\\\project_mlops\\\\notebooks'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b0c02bb0-a7a1-4c7c-8cfa-f9c644e7885c",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"C:/Users/Asus/Documents/GitHub/MLOps/project_mlops\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d5618feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/01_raw/booking.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "98a28085-2ba7-4414-97a1-c20bc5781b83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 36285 entries, 0 to 36284\n",
      "Data columns (total 17 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   Booking_ID                36285 non-null  object \n",
      " 1   number of adults          36285 non-null  int64  \n",
      " 2   number of children        36285 non-null  int64  \n",
      " 3   number of weekend nights  36285 non-null  int64  \n",
      " 4   number of week nights     36285 non-null  int64  \n",
      " 5   type of meal              36285 non-null  object \n",
      " 6   car parking space         36285 non-null  int64  \n",
      " 7   room type                 36285 non-null  object \n",
      " 8   lead time                 36285 non-null  int64  \n",
      " 9   market segment type       36285 non-null  object \n",
      " 10  repeated                  36285 non-null  int64  \n",
      " 11  P-C                       36285 non-null  int64  \n",
      " 12  P-not-C                   36285 non-null  int64  \n",
      " 13  average price             36285 non-null  float64\n",
      " 14  special requests          36285 non-null  int64  \n",
      " 15  date of reservation       36285 non-null  object \n",
      " 16  booking status            36285 non-null  object \n",
      "dtypes: float64(1), int64(10), object(6)\n",
      "memory usage: 4.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba74b253-e903-445f-bda8-7036a2e5e987",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "# **2.** Preprocessing\n",
    "\n",
    "<div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c13ab01-59ec-445a-94d5-148e9313a163",
   "metadata": {},
   "source": [
    "## **2.1** Data Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b802abc3-36d6-4017-af4b-f3e2bb5fece5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"booking status\"] = df[\"booking status\"].map({\n",
    "    \"Canceled\": 1,\n",
    "    \"Not_Canceled\": 0\n",
    "})\n",
    "\n",
    "# Split features and target\n",
    "X = df.drop(columns='booking status')\n",
    "y = df['booking status']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e22d7a60-e8d3-4abb-9cad-d4099b2d59d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Initial split (Train + Temp)\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# Step 2: Split Temp into Train and Validation\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.25, stratify=y_temp, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf4a78e4-7285-40f4-871b-f8c81925d10c",
   "metadata": {},
   "source": [
    "## **2.2** Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ef8805c1-e910-4fea-871d-8aa9f235e4c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify column types\n",
    "num_cols = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "cat_cols = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "\n",
    "# Define transformers\n",
    "numeric_transformer = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"mean\")),\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "])\n",
    "\n",
    "# Combine into a column transformer\n",
    "preprocessor = ColumnTransformer([\n",
    "    (\"num\", numeric_transformer, num_cols),\n",
    "    (\"cat\", categorical_transformer, cat_cols)\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# For tree-based models: imputation only, no scaling\n",
    "numeric_transformer_tree = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"mean\"))\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "])\n",
    "\n",
    "preprocessor_tree = ColumnTransformer([\n",
    "    (\"num\", numeric_transformer_tree, num_cols),\n",
    "    (\"cat\", categorical_transformer, cat_cols)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc55681-ee1e-4da9-9290-8229e15d8e6b",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "# **3.** Modeling\n",
    "\n",
    "<div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d9cc854-ae58-49aa-802e-cfc9de50797a",
   "metadata": {},
   "source": [
    "## **3.1** Logistic Regression\n",
    "Parameters to tune:\n",
    "\n",
    "| Parameter | Description                                                            | Common Values                      |\n",
    "| --------- | ---------------------------------------------------------------------- | ---------------------------------- |\n",
    "| `C`       | Inverse of regularization strength (smaller = stronger regularization) | `0.01`, `0.1`, `1`, `10`, `100`    |\n",
    "| `penalty` | Type of regularization                                                 | `'l1'`, `'l2'`, `'elasticnet'`     |\n",
    "| `solver`  | Optimization algorithm (depends on penalty)                            | `'liblinear'`, `'saga'`, `'lbfgs'` |\n",
    "\n",
    "- Attempt tuning with mlflow, so that we can record each model version?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a4e7034b-4a90-49a5-85bf-146adf412ad0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Results (Logistic Regression):\n",
      "___________________________________________________________________________________________________________\n",
      "                                            Confusion Matrix                                               \n",
      "[[4371  508]\n",
      " [ 797 1581]]\n",
      "___________________________________________________________________________________________________________\n",
      "                                       Classification Report                                               \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.90      0.87      4879\n",
      "           1       0.76      0.66      0.71      2378\n",
      "\n",
      "    accuracy                           0.82      7257\n",
      "   macro avg       0.80      0.78      0.79      7257\n",
      "weighted avg       0.82      0.82      0.82      7257\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logreg_pipe = Pipeline([\n",
    "    (\"preprocessing\", preprocessor),\n",
    "    (\"clf\", LogisticRegression(max_iter=1000, random_state=42))\n",
    "])\n",
    "\n",
    "\n",
    "# Train on train set\n",
    "logreg_pipe.fit(X_train, y_train)\n",
    "\n",
    "# Validate on validation set\n",
    "y_val_pred_lg = logreg_pipe.predict(X_val)\n",
    "print(\"Validation Results (Logistic Regression):\")\n",
    "print('___________________________________________________________________________________________________________')\n",
    "print('                                            Confusion Matrix                                               ')\n",
    "print(confusion_matrix(y_val, y_val_pred_lg))\n",
    "print('___________________________________________________________________________________________________________')\n",
    "print('                                       Classification Report                                               ')\n",
    "print(classification_report(y_val, y_val_pred_lg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "896d2ccb-8616-42fc-a0ce-5bf027653900",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Test Results (Logistic Regression):\n",
      "___________________________________________________________________________________________________________\n",
      "                                            Confusion Matrix                                               \n",
      "[[4416  463]\n",
      " [ 828 1550]]\n",
      "___________________________________________________________________________________________________________\n",
      "                                       Classification Report                                               \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.91      0.87      4879\n",
      "           1       0.77      0.65      0.71      2378\n",
      "\n",
      "    accuracy                           0.82      7257\n",
      "   macro avg       0.81      0.78      0.79      7257\n",
      "weighted avg       0.82      0.82      0.82      7257\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Final evaluation on test set\n",
    "y_test_pred_lg = logreg_pipe.predict(X_test)\n",
    "print(\"Final Test Results (Logistic Regression):\")\n",
    "print('___________________________________________________________________________________________________________')\n",
    "print('                                            Confusion Matrix                                               ')\n",
    "print(confusion_matrix(y_test, y_test_pred_lg))\n",
    "print('___________________________________________________________________________________________________________')\n",
    "print('                                       Classification Report                                               ')\n",
    "print(classification_report(y_test, y_test_pred_lg))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db53e46-e9a9-4442-82df-3fccf112c4b1",
   "metadata": {},
   "source": [
    "## **3.2** Decision Tree\n",
    "\n",
    "Possible parameters to tune:\n",
    "\n",
    "| Parameter           | Description                                    | Common Values                       |\n",
    "| ------------------- | ---------------------------------------------- | ----------------------------------- |\n",
    "| `max_depth`         | Maximum depth of the tree                      | `3`, `5`, `10`, `None`              |\n",
    "| `min_samples_split` | Min samples required to split an internal node | `2`, `5`, `10`                      |\n",
    "| `min_samples_leaf`  | Min samples required at a leaf node            | `1`, `5`, `10`                      |\n",
    "| `criterion`         | Function to measure split quality              | `'gini'`, `'entropy'`, `'log_loss'` |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a4ea21df-5196-4033-94ea-58473bb3a00e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Results (Decision Tree):\n",
      "___________________________________________________________________________________________________________\n",
      "                                            Confusion Matrix                                               \n",
      "[[4470  409]\n",
      " [ 506 1872]]\n",
      "___________________________________________________________________________________________________________\n",
      "                                       Classification Report                                               \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.92      0.91      4879\n",
      "           1       0.82      0.79      0.80      2378\n",
      "\n",
      "    accuracy                           0.87      7257\n",
      "   macro avg       0.86      0.85      0.86      7257\n",
      "weighted avg       0.87      0.87      0.87      7257\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the pipeline\n",
    "dt_pipe = Pipeline([\n",
    "    (\"preprocessing\", preprocessor_tree),\n",
    "    (\"clf\", DecisionTreeClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "# Fit on training data\n",
    "dt_pipe.fit(X_train, y_train)\n",
    "\n",
    "# Validate\n",
    "y_val_pred_dt = dt_pipe.predict(X_val)\n",
    "print(\"Validation Results (Decision Tree):\")\n",
    "print('___________________________________________________________________________________________________________')\n",
    "print('                                            Confusion Matrix                                               ')\n",
    "print(confusion_matrix(y_val, y_val_pred_dt))\n",
    "print('___________________________________________________________________________________________________________')\n",
    "print('                                       Classification Report                                               ')\n",
    "print(classification_report(y_val, y_val_pred_dt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "58abb7ef-6473-4259-8429-04bc5c09dc7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Test Results (Decision Tree):\n",
      "___________________________________________________________________________________________________________\n",
      "                                            Confusion Matrix                                               \n",
      "[[4511  368]\n",
      " [ 499 1879]]\n",
      "___________________________________________________________________________________________________________\n",
      "                                       Classification Report                                               \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.92      0.91      4879\n",
      "           1       0.84      0.79      0.81      2378\n",
      "\n",
      "    accuracy                           0.88      7257\n",
      "   macro avg       0.87      0.86      0.86      7257\n",
      "weighted avg       0.88      0.88      0.88      7257\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Final test\n",
    "y_test_pred_dt = dt_pipe.predict(X_test)\n",
    "print(\"Final Test Results (Decision Tree):\")\n",
    "print('___________________________________________________________________________________________________________')\n",
    "print('                                            Confusion Matrix                                               ')\n",
    "print(confusion_matrix(y_test, y_test_pred_dt))\n",
    "print('___________________________________________________________________________________________________________')\n",
    "print('                                       Classification Report                                               ')\n",
    "print(classification_report(y_test, y_test_pred_dt))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b0c69e-5c01-4e2e-9e60-8dcd3bc2ef07",
   "metadata": {},
   "source": [
    "## **3.3** Random Forest\n",
    "\n",
    "Possible parameters to tune:\n",
    "\n",
    "| Parameter           | Description                         | Common Values                |\n",
    "| ------------------- | ----------------------------------- | ---------------------------- |\n",
    "| `n_estimators`      | Number of trees in the forest       | `100`, `200`, `500`          |\n",
    "| `max_depth`         | Max depth of each tree              | `None`, `5`, `10`, `20`      |\n",
    "| `max_features`      | Features to consider when splitting | `'auto'`, `'sqrt'`, `'log2'` |\n",
    "| `min_samples_split` | Min samples to split a node         | `2`, `5`, `10`               |\n",
    "| `min_samples_leaf`  | Min samples at a leaf               | `1`, `5`, `10`               |\n",
    "| `bootstrap`         | Whether to use bootstrap samples    | `True`, `False`              |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "79afeb18-8aad-4aa3-a05a-4479f17a4e07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Validation Results (Random Forest):\n",
      "___________________________________________________________________________________________________________\n",
      "                                            Confusion Matrix                                               \n",
      "[[4658  221]\n",
      " [ 606 1772]]\n",
      "___________________________________________________________________________________________________________\n",
      "                                       Classification Report                                               \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.95      0.92      4879\n",
      "           1       0.89      0.75      0.81      2378\n",
      "\n",
      "    accuracy                           0.89      7257\n",
      "   macro avg       0.89      0.85      0.86      7257\n",
      "weighted avg       0.89      0.89      0.88      7257\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf_pipe = Pipeline([\n",
    "    (\"preprocessing\", preprocessor_tree),\n",
    "    (\"classifier\", RandomForestClassifier(n_estimators=100, random_state=42))\n",
    "])\n",
    "\n",
    "# Train on train set\n",
    "rf_pipe.fit(X_train, y_train)\n",
    "\n",
    "# Validate on validation set\n",
    "y_val_pred_rf = rf_pipe.predict(X_val)\n",
    "print(\"🔍 Validation Results (Random Forest):\")\n",
    "print('___________________________________________________________________________________________________________')\n",
    "print('                                            Confusion Matrix                                               ')\n",
    "print(confusion_matrix(y_val, y_val_pred_rf))\n",
    "print('___________________________________________________________________________________________________________')\n",
    "print('                                       Classification Report                                               ')\n",
    "print(classification_report(y_val, y_val_pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a9536850-5204-444d-bafd-6550dd05c4d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧪 Final Test Results (Random Forest):\n",
      "___________________________________________________________________________________________________________\n",
      "                                            Confusion Matrix                                               \n",
      "[[4678  201]\n",
      " [ 610 1768]]\n",
      "___________________________________________________________________________________________________________\n",
      "                                       Classification Report                                               \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.96      0.92      4879\n",
      "           1       0.90      0.74      0.81      2378\n",
      "\n",
      "    accuracy                           0.89      7257\n",
      "   macro avg       0.89      0.85      0.87      7257\n",
      "weighted avg       0.89      0.89      0.89      7257\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Final evaluation on test set\n",
    "y_test_pred_rf = rf_pipe.predict(X_test)\n",
    "print(\"🧪 Final Test Results (Random Forest):\")\n",
    "print('___________________________________________________________________________________________________________')\n",
    "print('                                            Confusion Matrix                                               ')\n",
    "print(confusion_matrix(y_test, y_test_pred_rf))\n",
    "print('___________________________________________________________________________________________________________')\n",
    "print('                                       Classification Report                                               ')\n",
    "print(classification_report(y_test, y_test_pred_rf))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a192df3-1935-4e9f-bdf4-95f57999c196",
   "metadata": {},
   "source": [
    "## **3.4** XGBoost\n",
    "\n",
    "Possible parameters to tune:\n",
    "\n",
    "| Parameter          | Description                        | Common Values               |\n",
    "| ------------------ | ---------------------------------- | --------------------------- |\n",
    "| `n_estimators`     | Number of boosting rounds (trees)  | `100`, `200`, `500`         |\n",
    "| `max_depth`        | Max depth of each tree             | `3`, `5`, `10`              |\n",
    "| `learning_rate`    | Step size shrinkage                | `0.01`, `0.1`, `0.2`, `0.3` |\n",
    "| `subsample`        | Fraction of rows used per tree     | `0.5`, `0.7`, `1`           |\n",
    "| `colsample_bytree` | Fraction of features used per tree | `0.5`, `0.7`, `1`           |\n",
    "| `gamma`            | Min loss reduction to split        | `0`, `1`, `5`               |\n",
    "| `reg_alpha`        | L1 regularization term             | `0`, `0.1`, `1`             |\n",
    "| `reg_lambda`       | L2 regularization term             | `0`, `0.1`, `1`             |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "733a92ca-3518-4be3-9321-e19108cd6b86",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [19:07:35] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Validation Results (XGBoost):\n",
      "___________________________________________________________________________________________________________\n",
      "                                            Confusion Matrix                                               \n",
      "[[4561  318]\n",
      " [ 557 1821]]\n",
      "___________________________________________________________________________________________________________\n",
      "                                       Classification Report                                               \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.93      0.91      4879\n",
      "           1       0.85      0.77      0.81      2378\n",
      "\n",
      "    accuracy                           0.88      7257\n",
      "   macro avg       0.87      0.85      0.86      7257\n",
      "weighted avg       0.88      0.88      0.88      7257\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xgb_pipe = Pipeline([\n",
    "    (\"preprocessing\", preprocessor_tree),\n",
    "    (\"classifier\", XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42))\n",
    "])\n",
    "\n",
    "# Train on train set\n",
    "xgb_pipe.fit(X_train, y_train)\n",
    "\n",
    "# Validate on validation set\n",
    "y_val_pred_xgb = xgb_pipe.predict(X_val)\n",
    "print(\"🔍 Validation Results (XGBoost):\")\n",
    "print('___________________________________________________________________________________________________________')\n",
    "print('                                            Confusion Matrix                                               ')\n",
    "print(confusion_matrix(y_val, y_val_pred_xgb))\n",
    "print('___________________________________________________________________________________________________________')\n",
    "print('                                       Classification Report                                               ')\n",
    "print(classification_report(y_val, y_val_pred_xgb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bc37599e-a941-42c6-bc5c-4eebbdf20567",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧪 Final Test Results (XGBoost):\n",
      "___________________________________________________________________________________________________________\n",
      "                                            Confusion Matrix                                               \n",
      "[[4592  287]\n",
      " [ 564 1814]]\n",
      "___________________________________________________________________________________________________________\n",
      "                                       Classification Report                                               \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.94      0.92      4879\n",
      "           1       0.86      0.76      0.81      2378\n",
      "\n",
      "    accuracy                           0.88      7257\n",
      "   macro avg       0.88      0.85      0.86      7257\n",
      "weighted avg       0.88      0.88      0.88      7257\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Final evaluation on test set\n",
    "y_test_pred_xgb = xgb_pipe.predict(X_test)\n",
    "print(\"🧪 Final Test Results (XGBoost):\")\n",
    "print('___________________________________________________________________________________________________________')\n",
    "print('                                            Confusion Matrix                                               ')\n",
    "print(confusion_matrix(y_test, y_test_pred_xgb))\n",
    "print('___________________________________________________________________________________________________________')\n",
    "print('                                       Classification Report                                               ')\n",
    "print(classification_report(y_test, y_test_pred_xgb))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4668bba8-8d72-4088-95f8-d7b522a9759c",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "# **4.** Wrap-up for Pipelines\n",
    "\n",
    "<div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99faf5a3-431d-4b12-9e5c-c89962197e21",
   "metadata": {},
   "source": [
    "#### Logistic Regression\n",
    "| Requirement              | Details                                                                               |\n",
    "| ------------------------ | ------------------------------------------------------------------------------------- |\n",
    "| **Feature Scaling**      | **Yes** – StandardScaler or MinMaxScaler is needed (especially for regularization). |\n",
    "| **Categorical Encoding** | **Yes** – Use One-Hot Encoding or Ordinal Encoding.                                 |\n",
    "| **Missing Values**       | **No** – Must be handled before training.                                           |\n",
    "| **Feature Selection**    | Optional – Helps prevent overfitting, especially with high-dimensional data.       |\n",
    "| **Feature Interaction**  | Not handled automatically – must be engineered manually.                            |\n",
    "\n",
    "#### Decision Trees\n",
    "\n",
    "| Requirement              | Details                                                              |\n",
    "| ------------------------ | -------------------------------------------------------------------- |\n",
    "| **Feature Scaling**      | **No** – Trees are scale-invariant.                                |\n",
    "| **Categorical Encoding** | **Yes** – Use Ordinal Encoding (not One-Hot for high cardinality). |\n",
    "| **Missing Values**       | Some implementations (e.g., `sklearn`) require imputation.        |\n",
    "| **Feature Selection**    | Built-in – Tree automatically selects relevant features.           |\n",
    "| **Feature Interaction**  | Handled internally by the tree splits.                             |\n",
    "\n",
    "\n",
    "#### Random Forest\n",
    "\n",
    "| Requirement              | Details                                                      |\n",
    "| ------------------------ | ------------------------------------------------------------ |\n",
    "| **Feature Scaling**      | **No**                                                     |\n",
    "| **Categorical Encoding** | **Yes** – Ordinal Encoding or One-Hot for low-cardinality. |\n",
    "| **Missing Values**       | Imputation needed unless using libraries that support it. |\n",
    "| **Feature Selection**    | Implicit – Less important features get low importance.     |\n",
    "| **Feature Interaction**  | Captures interactions via ensemble splits.                 |\n",
    "\n",
    "\n",
    "\n",
    "#### XGBoost\n",
    "\n",
    "\n",
    "| Requirement              | Details                                                                                                                       |\n",
    "| ------------------------ | ----------------------------------------------------------------------------------------------------------------------------- |\n",
    "| **Feature Scaling**      | **No**                                                     |\n",
    "| **Categorical Encoding** | **Yes**                                                    |\n",
    "| **Missing Values**       | **Yes** – Handled natively.                                |\n",
    "| **Feature Selection**    | Built-in regularization + importance metrics.              |\n",
    "| **Feature Interaction**  | Learns interactions automatically via boosting.            |\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
